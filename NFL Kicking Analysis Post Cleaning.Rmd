---
title: "NFL Kicking Analysis (Post-Cleaning)"
author: "Josh Garzaniti"
date: "2025-07-18"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Packages I used:
```{r}
library(ggplot2)
library(ggdark)
library(caret)
library(tidyverse)
library(tidyr)
library(stringr)
library(xgboost)
library(randomForest)
library(ggrepel)
library(nflreadr)
library(nflplotR)
library(nflfastR)
library(mice)
library(lme4)
library(arm)
library(car)
library(effects)
library(Matrix)
library(pROC)
library(SHAPforxgboost)

```


## Analysis
```{r}
pbp_complete = read.csv("G:/My Drive/Personal Projects/pbp_complete.csv")
```


Now we don't have to deal with missing data anymore. The next step is creating target variables. We already created on called "result" which in essence was just a make or miss variable based on if a kicker made their try attempt, but now let's make a derived variable based off of that value called probability, which is the probability of that kicker making that attempt.

P(x) we can determine a few ways:

we can group all of the attempts by distance, distance and weather, distance, weather turf condition, distance, weather, turf condition, temperature, and wind......or all of those and throw in the stadium. In that sense what we are doing is taking a historical average of how many attempts from that spot on that field in those conditions were made vs missed.....the thing we have to be smart about is not narrowing our sample size down too much to where we condense the number of tries going into the historical average. E.g say a there's only been one attempt at Lambeau field from 65 yards out, and miraculously the kicker made it.....on the next attempt from that location a kicker would be going up against a p(x) of 100% (which in theory says they should make that kick 100% of the time), yet we all know that's not factual in reality.

if we group up by:
distance
roof type
temperature
wind speed
and surface type
let's see what the empirical results of each attempt are:

```{r}
pbp_complete_grouped = pbp_complete%>%
  group_by(kick_distance, roof, temp, wind, surface)%>%
  mutate(probability_advanced = mean(result, na.rm = TRUE))%>%
  ungroup()

pbp_complete_grouped
```

A good baseline for this is to just check by distances (our probability should be dropping of drastically by distance so let's see what that distribution looks like)

```{r}
distance_vs_probability_plot = ggplot(pbp_complete_grouped, 
                                      mapping = aes(x = kick_distance,
                                                    y = probability_advanced))+
                                      geom_point()+
                                      geom_smooth()+
                                      dark_theme_minimal()+
                                      labs(title = "NFL Kick Distance vs Make Probability (advanced)", subtitle = "from 1999-2024", x = "Distance", y = "Probability")

distance_vs_probability_plot
```
What about binning vars like temp and wind?

```{r}
pbp_complete_binned = pbp_complete%>%
  mutate(
    temp_bin = cut(temp, breaks = c(-Inf, 30, 50, 70, 90, Inf), labels = c("cold", "chilly", "mild", "warm", "hot")),
    wind_bin = cut(wind, breaks = c(-Inf, 5, 10, 20, Inf), labels = c("calm", "breezy", "windy", "gusty")))%>%
  group_by(kick_distance, roof, temp_bin, wind_bin, surface)%>%
  mutate(
    group_n = n(),
    probability_advanced = ifelse(group_n >= 5, mean(result, na.rm = TRUE), NA_real_))%>%
  ungroup()%>%
  mutate(
    probability_advanced = ifelse(is.na(probability_advanced), mean(result, na.rm = TRUE), probability_advanced))
```

Visualizing this

```{r}
distance_vs_probability_plot_2 = ggplot(pbp_complete_binned, 
  aes(x = kick_distance, y = probability_advanced)) +
  geom_point(aes(size = group_n), alpha = 0.6) +
  geom_smooth() +
  geom_hline(
    yintercept = mean(pbp_complete$result, na.rm = TRUE), 
    linetype = "dashed", 
    color = "red", 
    alpha = 0.6)+
  dark_theme_minimal()+
  labs(
    title = "NFL Kick Distance vs Make Probability (advanced)", 
    subtitle = "from 1999-2024", 
    x = "Distance", 
    y = "Probability")

distance_vs_probability_plot_2
```

Facet Wrap by Roof type

```{r}
distance_vs_probability_roof = ggplot(pbp_complete_binned, 
  aes(x = kick_distance, y = probability_advanced))+
  geom_point(aes(size = group_n), alpha = 0.6)+
  geom_smooth(se = FALSE)+
  geom_hline(
    yintercept = mean(pbp_complete$result, na.rm = TRUE), 
    linetype = "dashed", color = "red", alpha = 0.6)+
  facet_wrap(~ roof)+
  dark_theme_minimal()+
  labs(
    title = "NFL Kick Distance vs Make Probability by Roof Type",
    subtitle = "From 1999–2024",
    x = "Distance",
    y = "Make Probability")

distance_vs_probability_roof
```

What about Surface type is there a relationship between distance and surface type when it comes to the probability of making kicks?

```{r}
distance_vs_probability_surface = ggplot(pbp_complete_binned, 
  aes(x = kick_distance, y = probability_advanced))+
  geom_point(aes(size = group_n), alpha = 0.6)+
  geom_smooth(se = FALSE) +
  geom_hline(
    yintercept = mean(pbp_complete$result, na.rm = TRUE), 
    linetype = "dashed", color = "red", alpha = 0.6)+
  facet_wrap(~ surface) +
  dark_theme_minimal() +
  labs(
    title = "NFL Kick Distance vs Make Probability by Field Surface",
    subtitle = "From 1999–2024",
    x = "Distance",
    y = "Make Probability")

distance_vs_probability_surface
```

#Early Analytical Questions

Here are some of the early questions I'm thinking about at this stage:

- in terms of general trends we can see that kicking accuracy has a negative relationship with distance (this makes sense and is our first check)

-kicking accuracy has strong(ger) negative relationships with distance in: closed, dome, and outdoor stadiums, but more of a logarithmic relationship with distance in open stadiums (research this)

-kicking accuracy on astroplay, astroturf, matrixturf, and sportturf surfaces appears to not have as drastic negative consequences over longer distances as field turf and grass (research what stadiums carry these types and if they're indoors or an even mix of different stadium types)

-dessograss and unknown surface types have almost a completely stable/level relationship with distance (this doesn't appear to be natural or make sense so more research is needed)


##Correlation Testing

Correlation between kick distance and make probability:
```{r}
distance_probability_cor = cor.test(pbp_complete_binned$kick_distance, pbp_complete_binned$probability_advanced)

distance_probability_cor
```
Strong Negative correlation (statistically significant) with distance and p(make).

Correlation between roof type and probability:
```{r}
roof_probability_cor = aov(probability_advanced ~ roof,data = pbp_complete_binned)

summary(roof_probability_cor)
```
This anova function tells us that roof type as a whole is significant in terms of its impact on p(make)

Going deeper:
```{r}
roof_probability_tukey = TukeyHSD(roof_probability_cor)

roof_probability_tukey
```
Results explained:
Kicks in dome stadiums are 0.65% more successful than closed stadiums
kicks in open stadiums are 1.24% more successful than closed stadiums
kicks in outdoor stadiums are 0.08% less successful than closed stadiums
kicks in outdoor stadiums are 1.50% less successful than dome stadiums
kicks in outdoor stadiums are 2.09% less successful than open stadiums

Conclusion ranking roof types for positive impact on kicking probabilities-
Dome and Open are the best
Closed are middle of the pack
Outdoor is significantly worse

```{r}
roof_prob_boxplot = ggplot(pbp_complete_binned, 
                             aes(x = roof, y = probability_advanced))+
                             geom_boxplot(fill = "skyblue", alpha = 0.7)+
                             dark_theme_minimal() +
                             labs(title = "Probability Advanced by Roof Type", 
                             x = "Roof Type", y = "Probability Advanced")

roof_prob_boxplot
```

Impact of surface type on kicking probability

I'm going to start with generic trends and then move onto brand types/names
```{r}
surface_type_probability_cor = aov(probability_advanced ~ surface_type,data = pbp_complete_binned)

summary(surface_type_probability_cor)
```
The type of surface used for fields is significant when it comes to making kicks

Tukey test surface types:
```{r}
surface_type_probability_tukey = TukeyHSD(surface_type_probability_cor)

surface_type_probability_tukey
```
Biggest significant takeaways-

Natural grass has ~1.85% less p(made) vs Artificial surfaces

Specific Brand/Surface Name tesing:
```{r}
surface_probability_cor = aov(probability_advanced ~ surface,data = pbp_complete_binned)

summary(surface_probability_cor)
```
Again we find that surface brands as a whole are significant in their relationship to kicking probability

Tukey test surface brands:
```{r}
surface_probability_tukey = TukeyHSD(surface_probability_cor)

surface_probability_tukey
```
Takeaways-

Natural Grass is significant worse than MatrixTurf, SportTurf, Dessograss, and Astroplay.

Dessograss, MatrixTurf, Astroplay are consistently beating other types.

FieldTurf and Astroturf have below average kicking probabilities.

Unknown brands/surface types are slightly worse than Astroplay and borderline worse than MatrixTurf, but not statistically different from Grass or SportTurf.

##Going back to probability and distance

remember in those charts earlier how I was seeing probability fit more of a logarithmic equation around distance rather than an exponential one?

Let's take a look at edge/fringe cases to see if longer kicks really do fit that pattern or what's really going on there.

```{r}
long_distance = pbp_complete_grouped%>%
  filter(kick_distance >= 50)
```

There are 3556 known attempts from 1999 onwards where a kick has been tried from 50+ yards.

What's the average make probability of those kicks as a whole:
```{r}
long_distance_average = mean(long_distance$probability_advanced)

long_distance_average
```
We can see that roughly 61.70% of kicks attempted from 50+ yards are made.

Broken down by yardage:
```{r}
long_distance_average_by_yard = long_distance%>%
  group_by(kick_distance)%>%
  summarise(average_probability = mean(probability_advanced),
            tries = n())

head(long_distance_average_by_yard, 10)
```

Plotting this out:
```{r}
long_distance_average_by_yard_plot = ggplot(long_distance_average_by_yard, 
                                            mapping = aes(x = kick_distance, 
                                                          y = average_probability))+
                                            geom_point(aes(size = tries))+
                                            geom_smooth()+
                                            dark_theme_minimal()+
                                            labs(title = "Probability of successful NFL field goal tries >= 50 yards", 
                                            subtitle = "since 1999", 
                                            x = "Yardage",
                                            y = "Probability")

long_distance_average_by_yard_plot
```

This makes much more sense so those fringe cases really aren't amounting to "better" kicking at longer distances....they're just minimal tries which should be fitting more of an exponential function over distance. 

So as a whole p(making a field goal over distance with respect to the number of tries (and not binning field goals) looks like this):
```{r}
distance_summary = pbp_complete_grouped%>%
  group_by(kick_distance)%>%
  summarise(
    average_probability = mean(probability_advanced, na.rm = TRUE),
    tries = n())


distance_vs_probability_plot_3 = ggplot(distance_summary, 
                                      aes(x = kick_distance,
                                          y = average_probability,
                                          size = tries))+
                                          geom_point(alpha = 0.6)+
                                          geom_smooth(se = FALSE)+
                                          dark_theme_minimal()+
                                          labs(title = "NFL Kick Distance vs Make Probability (Advanced)",
                                          subtitle = "from 1999–2024",
                                          x = "Distance (yards)",
                                          y = "Probability of make",
                                          size = "Attempts")

distance_vs_probability_plot_3
```

##Mixed Effect Modeling before scaling

One thing I want to do in this analysis is break down how how different players, teams, stadiums, roof types, and surfaces impact the expected kicker probabilities and make probability above expected.

Let's start off with a simple me model on kickers as a whole

```{r}
kicker_mixed_model = glmer(result ~ kick_distance + temp + roof + wind + surface + (1|kicker_player_name), 
                          data = pbp_complete, 
                          family = binomial)

summary(kicker_mixed_model)
```
Takeaways:
- std being 0.4489 shows that some kickers are better/worse than average
- +/- 0.45 log-odds translates to +/-11 percentage points in make probability
-temperature slightly increases your odds of making a kick
-wind slightly decreases your odds of making a kick
-none of the roof types or surface types are significant in terms of p(making a kick)


##Scaling

Scaling to a mean of 0 and a SD of 1
```{r}
pbp_complete$kick_distance_scaled = scale(pbp_complete$kick_distance)
pbp_complete$temp_scaled = scale(pbp_complete$temp)
pbp_complete$wind_scaled = scale(pbp_complete$wind)
```

##Mixed Effect Model with Scaling

```{r}
kicker_mixed_model = glmer(result ~ kick_distance_scaled + temp_scaled + roof + wind_scaled + surface + (1|kicker_player_name), 
                          data = pbp_complete, 
                          family = binomial, control = glmerControl(optimizer = "bobyqa"))

summary(kicker_mixed_model)
```
Takeaways after scaling:
-your odds of making a kick decrease by ~71.32% for each standard deviation (roughly 9 yards) increase from the average distance 
-odds actually increase by ~12.04% for every SD increase in temperature (~20 degrees)
-odds decrease ~10.17% for each SD increase in wind speed (~5.5mph)

##What are kicker-specific random effects?
```{r}
kicker_effects = ranef(kicker_mixed_model, condVar = TRUE)$kicker_player_name

kicker_effects = kicker_effects%>%
  arrange(desc(`(Intercept)`))

head(kicker_effects, 10)

tail(kicker_effects, 10)
```

The intercepts we see here display the impacts or effects individual kickers have on kick probability given roof type, temperature, wind speed, surface type and distance. So given all those variables guess who is head and shoulders above the rest of the league....Justin Tucker by a wide margin. Anything positive means above average and anything negative is under average

##Plotting Kicker Effects out

Lets filter down to current NFL kickers and get a gauge of who is performing above league average in terms of kick probability for all of these factors taken into consideration.


```{r}
random_effects_df = as.data.frame(kicker_effects)

random_effects_df$kicker = row.names(kicker_effects)
```


```{r}
standard_error_kicker = se.ranef(kicker_mixed_model)$kicker_player_name[,1]

random_effects_df$standard_error = standard_error_kicker

random_effects_df = random_effects_df%>%
  mutate(lower = `(Intercept)` - 1.96*standard_error,
         upper = `(Intercept)` + 1.96*standard_error)

```

Filtering down to current players
```{r}
random_effects_df = random_effects_df%>%
  filter(kicker %in% c("J.Bates", "J.Tucker", "C.Boswell", "C.Dicker", "B.Aubrey",
                       "C.McLaughlin", "J.Elliott", "T.Bass", "J.Sanders", "H.Butker",
                       "T.Loop", "K.Fairbairn", "C.Santos", "J.Karty", "M.Gay", "W.Lutz",
                       "E.McPherson", "D.Carlson", "B.McManus", "J.Myers", "W.Reichard",
                       "Y.Koo", "Z.Gonzalez", "J.Moody", "C.Little", "A.Borregales", 
                       "C.Ryland", "G.Gano", "D.Hopkins", "M.Wright", "S.Shrader", 
                       "B.Grupe", "J.Slye", "J.McAtamney", "J.Parker Romo", "C.Davis",
                       "A.Carlson", "G.Zuerlein", "N.Folk", "G.Joseph", "E.Pineiro", 
                       "A.Seibert", "M.Prater", "B.Narveson", "L.Havrisik", "C.York",
                       "T.Brown", "C.Dunn", "R.Bullock", "B.Maher", "M.Ammendola", 
                       "N.Sciba", "J.Garibay", "R.Patterson", "J. McCourt", "C.Shudak", "M.Badgley"))
```



Plot
```{r}
Kicker_Random_Effects_plot1 = ggplot(random_effects_df, aes(x = reorder(kicker, `(Intercept)`), y = `(Intercept)`))+
  geom_point()+
  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.2)+
  coord_flip()+
  geom_hline(yintercept = 0, linetype = "dashed")+
  dark_theme_minimal()+
  labs(title = "Current NFL Kicker-Specific Random Effects with 95% CI",
       y = "Random Intercept (Effect on Log-Odds)",
       x = "Kicker") 

Kicker_Random_Effects_plot1

```
Looking at the plot in terms of P(making a kick)
```{r}
probability_function = function(logit){
  plogis(logit)
}


random_effects_probability_df = random_effects_df%>%
  mutate(probability = probability_function(`(Intercept)`))%>%
  arrange(desc(probability))

head(random_effects_probability_df, 10)
```

Plotting
```{r}
mean_prob = mean(random_effects_probability_df$probability, na.rm = TRUE)

Kicker_Random_Effects_prob = ggplot(random_effects_probability_df, aes(x = reorder(kicker, probability), y = probability)) +
  geom_hline(yintercept = mean_prob, linetype = "dashed") +
  geom_point() +
  coord_flip() +
  dark_theme_minimal() +
  labs(title = "Current NFL Kicker-Specific Random Effects", 
       subtitle = "In terms of probability of making a kick",
       y = "Probability",
       x = "Kicker")

Kicker_Random_Effects_prob
```

Highlighting specific players

```{r}
highlighted_kicker = "W.Lutz" #Just change this to the kicker you want to study

random_effects_probability_df = random_effects_probability_df%>%
  mutate(highlight = ifelse(kicker == highlighted_kicker, "Highlighted", "Other"))

mean_prob = mean(random_effects_probability_df$probability, na.rm = TRUE)

ggplot(random_effects_probability_df, aes(x = reorder(kicker, probability), 
                                          y = probability, 
                                          fill = highlight))+
  geom_col(show.legend = FALSE)+
  geom_hline(yintercept = mean_prob, linetype = "dashed")+
  coord_flip()+
  scale_fill_manual(values = c("Highlighted" = "orange", "Other" = "gray70"))+
  dark_theme_minimal()+
  labs(title = "Kicker-Specific Random Effects", 
       subtitle = "In terms of probability of making a kick",
       y = "Probability",
       x = "Kicker")

```

##Modeling with Surface Type instead of Surface
I want to try and run another model but this time with surface (artificial or real), instead of the specific brand of surface type used to capture general trends.

```{r}
kicker_mixed_model2 = glmer(result ~ kick_distance_scaled + temp_scaled + roof + wind_scaled + surface_type + (1|kicker_player_name), 
                          data = pbp_complete, 
                          family = binomial, control = glmerControl(optimizer = "bobyqa"))

summary(kicker_mixed_model2)
```
-according to this model, natural grass has a slightly more negative impact on make probability vs artificial surfaces, but it's not statistically significant.

##Next Modeling Steps

Add game_seconds_remaining, score differential, quarter.

Add distance * wind interaction.

Consider random slope for distance per kicker.

Check AIC / model fit improvements.

Check for multicollinearity (VIF) after adding interactions.

Mutating to create a score differential variable and a score differential type variable
```{r}
pbp_complete = pbp_complete%>%
  mutate(score_differential = abs(total_home_score - total_away_score),
         score_differential_type = case_when(
           score_differential == 0 ~ "Tied",
           score_differential <= 7 ~ "One Possession",
           score_differential > 7 & score_differential <= 14 ~ "Close",
           score_differential > 14 ~ "Blowout"))

pbp_complete$score_differential_type = factor(pbp_complete$score_differential_type,
           levels = c("Tied", "One Possession", "Close", "Blowout"))

pbp_complete = pbp_complete%>%
  mutate(score_differential = as.numeric(score_differential))
  
```


Modeling with Score Differential
```{r}
kicker_mixed_model3 = glmer(result ~ kick_distance_scaled + temp_scaled + roof + wind_scaled + surface_type + score_differential +(1|kicker_player_name), 
                          data = pbp_complete, 
                          family = binomial, control = glmerControl(optimizer = "bobyqa"))

summary(kicker_mixed_model3)
```

We can see that score differential is very significant in terms of individual kickers making their kicks. In fact for each point increase in the score differential, kickers increase their odds of making an individual kick by 2.06%


Plotting this out
```{r}

prob_by_score_diff = pbp_complete%>%
  group_by(score_differential)%>%
  summarise(prob_make = mean(result))

score_differential_make_plot = ggplot(prob_by_score_diff, aes(x = score_differential, y = prob_make)) +
  geom_point() +
  geom_smooth(method = "glm", method.args = list(family = "binomial")) +
  dark_theme_minimal() +
  labs(title = "Impact of Score Differential on NFL Kick Probability",
       subtitle = "1999-2024",
       x = "Score Differential",
       y = "Probability of Make")

score_differential_make_plot
```





Quick Multi-collinearity check
```{r}
kicker_glm_fixed = glm(result ~ kick_distance_scaled + temp_scaled + roof + wind_scaled + surface_type + score_differential,
                       data = pbp_complete,
                       family = binomial)
vif(kicker_glm_fixed)
```

All of my VIF levels are under 2 which is great to see in terms of having variables in my model

Next model
```{r}
kicker_mixed_model4 = glmer(result ~ kick_distance_scaled + temp_scaled + roof + wind_scaled + surface_type + score_differential_type +(1|kicker_player_name), 
                          data = pbp_complete, 
                          family = binomial, control = glmerControl(optimizer = "bobyqa"))

summary(kicker_mixed_model4)
```
Last Mixed Effects Model
```{r}
kicker_mixed_model5 = glmer(result ~ kick_distance_scaled + 
                              temp_scaled + 
                              roof + 
                              wind_scaled + 
                              surface_type + 
                              score_differential_type + 
                              quarter_seconds_remaining +
                              half_seconds_remaining + 
                              game_seconds_remaining + 
                              (1|kicker_player_name), 
                          data = pbp_complete, 
                          family = binomial, control = glmerControl(optimizer = "bobyqa"))

summary(kicker_mixed_model5)
```

Here we can see that time remaining in a quarter, half, and game doesn't have a significant impact on a kicker's make probability.

Visualzing effects
```{r}
score_diff_effect = Effect("score_differential_type", kicker_mixed_model4)

kick_dist_effect = Effect("kick_distance_scaled", kicker_mixed_model4)

temp_effect = Effect("temp_scaled", kicker_mixed_model4)

roof_effect = Effect("roof", kicker_mixed_model4)

wind_effect = Effect("wind_scaled", kicker_mixed_model4)

surface_type_effect = Effect("surface_type", kicker_mixed_model4)

```

score differential
```{r}
plot(score_diff_effect)
```

distance
```{r}
plot(kick_dist_effect)
```

temperature
```{r}
plot(temp_effect)
```

roof types
```{r}
plot(roof_effect)
```

wind speed
```{r}
plot(wind_effect)
```

surface type
```{r}
plot(surface_type_effect)
```

```{r}
predictive_data = pbp_complete_grouped%>%
  mutate(score_differential = abs(total_home_score - total_away_score),
         score_differential_type = case_when(
           score_differential == 0 ~ "Tied",
           score_differential <= 7 ~ "One Possession",
           score_differential > 7 & score_differential <= 14 ~ "Close",
           score_differential > 14 ~ "Blowout"),
         roof = as.factor(roof),
         score_differential_type = as.factor(score_differential_type),
         kick_distance = as.numeric(kick_distance),
         wind = as.numeric(wind),
         temp = as.numeric(temp),
         result = as.numeric(result),
         kicker_player_name = as.factor(kicker_player_name))%>%
  dplyr::select(result, kicker_player_name, kick_distance, wind, roof, temp,  score_differential_type, probability_advanced)

```


##Building Predictive models with our Significant Variables

```{r}
#make the training data of our model everything except our target var
predictive_data_model = model.matrix(result ~ . -1, data = predictive_data)

#make the result of the kick the target var
labels = predictive_data$result
```

Train/test split
```{r}
set.seed(303)
xgbtrain_index = createDataPartition(labels, p = 0.8, list = FALSE)

xgbtrain_data = predictive_data_model[xgbtrain_index, ]
xgbtrain_labels = labels[xgbtrain_index]

xgbtest_data = predictive_data_model[-xgbtrain_index, ]
xgbtest_labels = labels[-xgbtrain_index]
```

Convert it to a matrix
```{r}
xgbdtrain = xgb.DMatrix(data = xgbtrain_data, label = xgbtrain_labels)
xgbdtest = xgb.DMatrix(data = xgbtest_data, label = xgbtest_labels)
```

#First XGB Predictive model
```{r}
xgb_model1 = xgboost(data = xgbdtrain, 
                    objective = "binary:logistic", 
                    eval_metric = "logloss", 
                    nrounds = 100, 
                    verbose = 1)
```

Test the trained model
```{r}
pred_xgb1 = predict(xgb_model1, xgbdtest)
```

Accuracy of the First XGBoost Model
```{r}
aucxgb1 = roc(xgbtest_labels, pred_xgb1)
print(paste("AUC:", aucxgb1$auc))
```

Variable Importance
```{r}
X_train_df <- as.data.frame(as.matrix(xgbtrain_data))

shap_values = shap.values(xgb_model = xgb_model1, X_train = X_train_df)
shap_long = shap.prep(shap_contrib = shap_values$shap_score, X_train = X_train_df)


shap.plot.summary(shap_long)
```

```{r}
shap_matrix = predict(xgb_model1, xgbtrain_data, predcontrib = TRUE)


shap_df = as.data.frame(shap_matrix)

top10_shap = sort(summary_shap, decreasing = TRUE)[1:10]

barplot(top10_shap, las = 2, main = "Top 10 SHAP Feature Importance", col = "steelblue")
```


